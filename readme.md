# Proyecto CDP

Repositorio enfocado en la **fase de modelado** de un caso de **riesgo crediticio**, cuyo objetivo es predecir si un cliente es **apto o no apto para crÃ©dito** a partir de informaciÃ³n histÃ³rica.  
El proyecto sigue una estructura tipo **MLOps pipeline**, separando datos, cÃ³digo, modelos y resultados para facilitar reproducibilidad, trazabilidad y escalabilidad.

---

## Objetivo del proyecto

- Construir un flujo completo de **preparaciÃ³n de datos â†’ entrenamiento â†’ evaluaciÃ³n â†’ despliegue (base) â†’ monitoreo (base)**.
- Entrenar y comparar modelos de machine learning para seleccionar el **mejor modelo** segÃºn desempeÃ±o y consistencia.
- Almacenar artefactos del pipeline (datasets procesados, modelos y mÃ©tricas) de forma organizada.

---

## Estructura del repositorio

La estructura real del repositorio es la siguiente:

```text
repo_modelado_ClaraO/
â””â”€â”€ mlops_pipeline/
    â”œâ”€â”€ data/                # Datasets procesados y artefactos de datos
    â”œâ”€â”€ models/              # Modelos entrenados y serializados
    â”œâ”€â”€ results/             # MÃ©tricas, reportes y resultados
    â””â”€â”€ src/                 # CÃ³digo fuente y notebooks
        â”œâ”€â”€ BD_creditos.xlsx
        â”œâ”€â”€ Cargar_datos.ipynb
        â”œâ”€â”€ comprension_eda.ipynb
        â”œâ”€â”€ config.json
        â”œâ”€â”€ ft_engineering.py
        â”œâ”€â”€ heuristic_model.py
        â”œâ”€â”€ model_training.py
        â”œâ”€â”€ model_evaluation.py
        â”œâ”€â”€ model_deploy.py
        â””â”€â”€ model_monitoring.py


ğŸ“¦ Dataset

UbicaciÃ³n: mlops_pipeline/src/BD_creditos.xlsx

El dataset contiene informaciÃ³n histÃ³rica de clientes y su comportamiento crediticio.
Incluye variables sociodemogrÃ¡ficas y financieras, asÃ­ como la variable objetivo que indica si una persona es apta o no apta para crÃ©dito.

â¸»

ğŸ” AnÃ¡lisis Exploratorio de Datos (EDA)

Archivo: mlops_pipeline/src/comprension_eda.ipynb

En esta etapa se realiza:
	â€¢	ExploraciÃ³n de la estructura del dataset
	â€¢	IdentificaciÃ³n de valores nulos y atÃ­picos
	â€¢	AnÃ¡lisis de distribuciones de variables
	â€¢	ExploraciÃ³n de la variable objetivo
	â€¢	DefiniciÃ³n de criterios para limpieza y transformaciÃ³n de datos

Los resultados del EDA guÃ­an las decisiones del feature engineering.

â¸»

âš™ï¸ Feature Engineering

Archivo: mlops_pipeline/src/ft_engineering.py

Este script se encarga de preparar los datos para el modelado:
	â€¢	Limpieza de datos
	â€¢	Manejo de valores nulos
	â€¢	CodificaciÃ³n de variables categÃ³ricas
	â€¢	Escalamiento de variables numÃ©ricas (cuando aplica)
	â€¢	GeneraciÃ³n de datasets listos para entrenamiento

Salidas esperadas:
Los datasets transformados se almacenan en mlops_pipeline/data/.

Modelo heurÃ­stico (baseline)

Archivo: mlops_pipeline/src/heuristic_model.py

Se implementa un modelo base heurÃ­stico que sirve como punto de comparaciÃ³n para los modelos de machine learning.
Permite validar que los modelos entrenados aportan una mejora real frente a reglas simples.

â¸»

ğŸ¤– Entrenamiento y selecciÃ³n de modelos

Archivo: mlops_pipeline/src/model_training.py

En esta etapa se:
	â€¢	Entrenan distintos modelos de machine learning
	â€¢	EvalÃºan mediante mÃ©tricas apropiadas
	â€¢	Comparan resultados entre modelos
	â€¢	Selecciona el mejor modelo, considerando desempeÃ±o y consistencia

Salidas esperadas:
	â€¢	Modelo seleccionado almacenado en mlops_pipeline/models/
	â€¢	MÃ©tricas y resultados en mlops_pipeline/results/

## ğŸ” Calidad de cÃ³digo y anÃ¡lisis estÃ¡tico

Durante el desarrollo del proyecto se realizaron pruebas de **calidad de cÃ³digo** utilizando **SonarCloud**, con el objetivo de evaluar:

- Calidad y mantenibilidad del cÃ³digo
- DetecciÃ³n de code smells
- Posibles vulnerabilidades
- Buenas prÃ¡cticas de desarrollo

Estas validaciones permiten asegurar que el cÃ³digo cumple con estÃ¡ndares adecuados para su integraciÃ³n en un entorno productivo y facilitan su escalabilidad y mantenimiento.
