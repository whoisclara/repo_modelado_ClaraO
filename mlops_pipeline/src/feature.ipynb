{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpia_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Limpieza inicial: reglas de validación, eliminar columnas redundantes, manejar valores faltantes, \n",
    "    ajustar rangos.\"\"\"\n",
    "\n",
    "    #Códigos de tipo credito con muy pocos registros\n",
    "    df[\"tipo_credito\"] = df[\"tipo_credito\"].where(~df[\"tipo_credito\"].isin([7, 68]), np.nan)\n",
    "\n",
    "    # Convertir a NaN las edades mayores a 100\n",
    "    df.loc[df[\"edad_cliente\"] > 100, \"edad_cliente\"] = np.nan\n",
    "\n",
    "    #Validar rango del puntaje de datacredito\n",
    "    df[\"puntaje_datacredito\"] = df[\"puntaje_datacredito\"].where(\n",
    "    (df[\"puntaje_datacredito\"] >= 150) & (df[\"puntaje_datacredito\"] <= 950),\n",
    "    np.nan)\n",
    "\n",
    "    #Imputación por filas\n",
    "    fil=[\"puntaje_datacredito\",\"saldo_mora\", \"edad_cliente\",\"saldo_total\", \"tipo_credito\"]\n",
    "    df=df.dropna(subset=fil)\n",
    "\n",
    "    # Variables con un alto valor de nulos\n",
    "    df = df.drop(\"tendencia_ingresos\", axis=1)\n",
    "\n",
    "    ##Imputación de nulos para promedio_ingresos_dataredito con factores calculados en el EDA\n",
    "    df[\"promedio_ingresos_datacredito\"] = df[\"promedio_ingresos_datacredito\"].replace(0, np.nan)\n",
    "\n",
    "    factores = {\"independiente\": 0.25,\"empleado\": 0.72}\n",
    "\n",
    "    def estimar_ingreso(row):\n",
    "        if pd.isna(row[\"promedio_ingresos_datacredito\"]):\n",
    "            factor = factores.get(str(row[\"tipo_laboral\"]).lower(), 1.0)\n",
    "            return row[\"salario_cliente\"] * factor\n",
    "        else:\n",
    "            return row[\"promedio_ingresos_datacredito\"]\n",
    "    \n",
    "    df[\"promedio_ingresos_datacredito\"] = df.apply(estimar_ingreso, axis=1)\n",
    "\n",
    "    df = df.loc[~((df[\"promedio_ingresos_datacredito\"] == 0) & (df[\"salario_cliente\"] == 0))]\n",
    "    \n",
    "    #Imputar de variables redundantes\n",
    "    df = df.drop(columns=[\"saldo_mora_codeudor\", \"saldo_principal\", \n",
    "                 \"puntaje\", \"creditos_sectorFinanciero\",\"salario_cliente\"], errors=\"ignore\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_type(X: pd.DataFrame):\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    var_bin = [c for c in cat_cols if X[c].nunique() == 2]\n",
    "    var_poli = [c for c in cat_cols if X[c].nunique() > 2]\n",
    "    var_num = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    return var_bin, var_poli, var_num\n",
    "\n",
    "def pipeline_noscale(var_bin, var_poli,var_num):\n",
    "    return ColumnTransformer([\n",
    "        (\"bin\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), var_bin),\n",
    "        (\"poly\", OneHotEncoder(handle_unknown=\"ignore\"), var_poli),\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), var_num)])\n",
    "\n",
    "def pipeline_scale(var_bin, var_poli,var_num):\n",
    "    return ColumnTransformer([\n",
    "        (\"bin\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), var_bin),\n",
    "        (\"poly\", OneHotEncoder(handle_unknown=\"ignore\"), var_poli),\n",
    "        (\"num\", MinMaxScaler(), var_num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(X,y,pipeline):\n",
    "    \"\"\"Aplicar transformaciones a los datos.\"\"\"\n",
    "\n",
    "    #Aplica el pipeline\n",
    "    X_transformed = pipeline.fit_transform(X)\n",
    "\n",
    "    # Convertir a array si es una matriz dispersa\n",
    "    if issparse(X_transformed):\n",
    "        X_transformed = X_transformed.toarray()\n",
    "\n",
    "    # Obtener nombres de las columnas transformadas\n",
    "    col_names= pipeline.get_feature_names_out()\n",
    "\n",
    "    # Crear un DataFrame con las características transformadas\n",
    "    X_df = pd.DataFrame(X_transformed, columns=col_names)\n",
    "\n",
    "    df_transformed= pd.concat([X_df, y.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame, target: str, test_size: float=0.2, random_state: int=42):\n",
    "    \"\"\"Dividir los datos en conjuntos de entrenamiento y prueba.\"\"\"\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path().resolve().parent / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df: pd.DataFrame, target: str):\n",
    "\n",
    "    df=limpia_data(df)\n",
    "\n",
    "    X= df.drop(columns=[target])\n",
    "    y= df[target]\n",
    "\n",
    "    var_bin, var_poli, var_num= define_type(X)\n",
    "\n",
    "    pipe_noscale= pipeline_noscale(var_bin, var_poli,var_num)\n",
    "    pipe_scale= pipeline_scale(var_bin, var_poli,var_num)\n",
    "\n",
    "    df_noscale= transform_data(X,y,pipe_noscale)\n",
    "    df_scale= transform_data(X,y,pipe_scale)\n",
    "\n",
    "    X_train, X_test, y_train, y_test= split_data(df_scale,target)\n",
    "    df_noscale.to_csv(DATA_DIR / \"df_sin_escalar.csv\", index=False)\n",
    "    df_scale.to_csv(DATA_DIR / \"df_escalado.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path().resolve().parent / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    df = pd.read_csv(DATA_DIR / \"df_post_eda.csv\")\n",
    "    main(df, target=\"Pago_atiempo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10763 entries, 0 to 10762\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   tipo_credito                   10760 non-null  float64\n",
      " 1   capital_prestado               10763 non-null  float64\n",
      " 2   plazo_meses                    10763 non-null  int64  \n",
      " 3   edad_cliente                   10613 non-null  float64\n",
      " 4   tipo_laboral                   10763 non-null  object \n",
      " 5   salario_cliente                10763 non-null  int64  \n",
      " 6   total_otros_prestamos          10763 non-null  int64  \n",
      " 7   cuota_pactada                  10763 non-null  int64  \n",
      " 8   puntaje                        10763 non-null  float64\n",
      " 9   puntaje_datacredito            10604 non-null  float64\n",
      " 10  cant_creditosvigentes          10763 non-null  int64  \n",
      " 11  huella_consulta                10763 non-null  int64  \n",
      " 12  saldo_mora                     10607 non-null  float64\n",
      " 13  saldo_total                    10607 non-null  float64\n",
      " 14  saldo_principal                10358 non-null  float64\n",
      " 15  saldo_mora_codeudor            10173 non-null  float64\n",
      " 16  creditos_sectorFinanciero      10763 non-null  int64  \n",
      " 17  creditos_sectorCooperativo     10763 non-null  int64  \n",
      " 18  creditos_sectorReal            10763 non-null  int64  \n",
      " 19  promedio_ingresos_datacredito  7833 non-null   float64\n",
      " 20  tendencia_ingresos             7773 non-null   object \n",
      " 21  Pago_atiempo                   10763 non-null  int64  \n",
      "dtypes: float64(10), int64(10), object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10590 entries, 0 to 10589\n",
      "Data columns (total 16 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   bin__tipo_laboral_Independiente     10590 non-null  float64\n",
      " 1   num__tipo_credito                   10590 non-null  float64\n",
      " 2   num__capital_prestado               10590 non-null  float64\n",
      " 3   num__plazo_meses                    10590 non-null  float64\n",
      " 4   num__edad_cliente                   10590 non-null  float64\n",
      " 5   num__total_otros_prestamos          10590 non-null  float64\n",
      " 6   num__cuota_pactada                  10590 non-null  float64\n",
      " 7   num__puntaje_datacredito            10590 non-null  float64\n",
      " 8   num__cant_creditosvigentes          10590 non-null  float64\n",
      " 9   num__huella_consulta                10590 non-null  float64\n",
      " 10  num__saldo_mora                     10590 non-null  float64\n",
      " 11  num__saldo_total                    10590 non-null  float64\n",
      " 12  num__creditos_sectorCooperativo     10590 non-null  float64\n",
      " 13  num__creditos_sectorReal            10590 non-null  float64\n",
      " 14  num__promedio_ingresos_datacredito  10590 non-null  float64\n",
      " 15  Pago_atiempo                        10590 non-null  int64  \n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv(DATA_DIR / \"df_escalado.csv\")\n",
    "df1.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_pipeline-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
